name: 'Deploy Docker to AWS (EC2)'
description: 'Deploy a Docker app to an AWS Virtual Machine (EC2) with Docker Compose'
branding:
  icon: upload-cloud
  color: red
inputs:
  # Checkout
  checkout:
    description: 'Specifies if this action should checkout the code'
    required: false
    default: 'true'
  
  # AWS
  aws_access_key_id:
    description: 'AWS access key ID'
    required: true
  aws_secret_access_key:
    description: 'AWS secret access key'
    required: true
  aws_session_token:
    description: 'AWS session token'
    required: false
  aws_default_region:
    description: 'AWS default region'
    default: us-east-1
    required: false
  aws_ami_id:
    description: 'AWS AMI ID. Will default to the latest Ubuntu 22.04 server image (HVM) '
    required: false
  tf_state_bucket:
    description: 'AWS S3 bucket to use for Terraform state. Defaults to `${org}-${repo}-{branch}-tf-state`'
    required: false
  tf_state_bucket_destroy:
    description: 'Force purge and deletion of S3 bucket defined. Any file contained there will be destroyed. `stack_destroy` must also be `true`'
    required: false
    default: 'false'
  aws_resource_identifier:
    description: 'Set to override the AWS resource identifier for the deployment.  Defaults to `${org}-{repo}-{branch}`.  Use with destroy to destroy specific resources.'
  
  # ENV files
  repo_env:
    description: 'File containing environment variables to be used with the app'
    required: false
    default: 'repo_env'
  dot_env:
    description: '`.env` file to be used with the app from Github secrets'
    required: false
  ghv_env:
    description: '`.env` file to be used with the app from Github variables'
    required: false
  aws_secret_env:
    description: 'Secret name to pull env variables from AWS Secret Manager'
    required: false
    default: ''
  
  # Application
  docker_remove_orphans:
    description: 'Toggle --remove-orphans flag. Defaults to false.'
    required: false
  docker_full_cleanup:
    description: 'Set to true to run docker-compose down and docker system prune --all --force --volumes after.'
    required: false
  app_directory:
    description: 'Relative path for the directory of the app (i.e. where `Dockerfile` and `docker-compose.yaml` files are located). This is the directory that is copied to the EC2 instance.  Default is the root of the repo. Add a .gha-ignore file with a list of files to be exluded.'
  app_directory_cleanup:
    description: 'Will generate a timestamped compressed file and delete the app repo directory.'
    required: false
  app_port:
    description: 'Port to expose for the app'
    required: false
  lb_port:
    description: 'Load balancer listening port. Defaults to 80 if NO FQDN provided, 443 if FQDN provided'
    required: false
  lb_healthcheck: 
    description: 'Load balancer health check string. Defaults to HTTP:app_port'
    required: false
  
  # EC2 Instance
  ec2_instance_profile:
    description: 'The AWS IAM instance profile to use for the EC2 instance'
  ec2_instance_type: 
    description: 'The AWS Instance type'
    required: false
  ec2_volume_size: 
    description: 'The size of the volume (in GB) on the AWS Instance'
    required: false
    default: "8"

  # EFS
  aws_create_efs:
    description: "Toggle to indicate whether to create and EFS and mount it to the ec2 as a part of the provisioning. Note: The EFS will be managed by the stack and will be destroyed along with the stack"
  aws_create_ha_efs:
    description: Toggle to indicate whether the EFS resource should be highly available (target mounts in all available zones within region)
  aws_create_efs_replica:
    description: Toggle to indiciate whether a read-only replica should be created for the EFS primary file system
  aws_enable_efs_backup_policy:
    description: Toggle to indiciate whether the EFS should have a backup policy, default is `false`
  aws_efs_zone_mapping:
    description: Information on Zone Mapping can be found in the [README.md](README.md#efs-zone-mapping)
  aws_efs_transition_to_inactive:
    description: Indicates how long it takes to transition files to the IA storage class
  aws_replication_configuration_destination:
    description: "AWS Region to target for replication"
  aws_mount_efs_id:
    description: ID of existing EFS
  aws_mount_efs_security_group_id:
    description: ID of the primary security group used by the existing EFS
  
  # Stack management
  stack_destroy:
    description: 'Set to "true" to Destroy the stack. Will delete the elb_logs bucket after the destroy action runs.'
  ansible_start_docker_timeout:
    description: 'Ammount of time in seconds it takes Ansible to mark as failed the startup of docker. Defaults to `300`'
    required: false
  
  # Domains
  domain_name:
    description: 'Define the root domain name for the application. e.g. app.com'
    required: false
  sub_domain:
    description: 'Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`'
  root_domain:
    description: 'Deploy to root domain. Will generate two DNS recrods, one for root, another for www'
    required: false
  cert_arn:
    description: 'Define the certificate ARN to use for the application'
    required: false
  create_root_cert:
    description: 'Generates and manage the root cert for the application'
    required: false
  create_sub_cert: 
    description: 'Generates and manage the sub-domain certificate for the application'
    required: false
  no_cert:
    description: 'Makes the application not to use a certificate by disabling certificate lookup.'
    required: false
    
  # Terraform
  targets:
    description: 'A list of targets to create before the full stack creation. Example: `'
  additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false
   
  # Secret Manager
  create_keypair_sm_entry:
    required: false
    description: "Generates and manages a secret manager entry that contains the public and private keys created for the ec2 instance."
    default: false
    
  # RDS
  aws_enable_postgres:
    description: Set to "true" to enable a postgres database
    required: false
  aws_postgres_engine: 
    description: Which Database engine to use
    required: false
  aws_postgres_engine_version:
    description: Specify Postgres version 
    required: false
  aws_postgres_instance_class:
    description: Define the size of the instances in the DB cluster
    required: false
  aws_postgres_subnets:
    description: 'Specify which subnets to use as a list of strings.  Example: `i-1234,i-5678,i-9101`'
    required: false
  aws_postgres_database_name:
    description: 'Specify a database name. Will be created if it does not exist'
    required: false
    # TODO: create another user and point to that instead
  aws_postgres_database_port:
    description: 'Postgres database port'
    required: false
  aws_postgres_database_group_family:
    description: 'Postgres database group family'
    required: false 
  aws_postgres_database_protection:
    description: 'Protects the database from deletion.'
    required: false
  aws_postgres_database_final_snapshot:
    description: 'Generates a snapshot of the database before deletion.'
    required: false

  # Ansible
  application_mount_target:
    description: "Directory path in application env to mount directory, default is `data`"
    default: data
  data_mount_target:
    description: "Directory path within docker env to mount directory to, default is `/data`"
  efs_mount_target:
    description: "Directory path in efs to mount directory to, default is `/`"

outputs:
  vm_url:
    description: "The URL of the generated app"
    value: ${{ steps.deploy.outputs.vm_url }}

runs:
  using: 'composite'
  steps:
    - name: Checkout if required
      if: ${{ inputs.checkout == 'true' }}
      uses: actions/checkout@v3

    - name: Deploy with BitOps
      id: deploy
      shell: bash
      env:
        GITHUB_ACTION_PATH: ${{ github.action_path }}
        BITOPS_ENVIRONMENT: deployment
        TERRAFORM_TARGETS: ${{ inputs.targets }}
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        AWS_SESSION_TOKEN: ${{ inputs.aws_session_token }}
        AWS_DEFAULT_REGION: ${{ inputs.aws_default_region }}
        AWS_AMI_ID: ${{ inputs.aws_ami_id }}
        TF_STATE_BUCKET: ${{ inputs.tf_state_bucket }}
        TF_STATE_BUCKET_DESTROY: ${{ inputs.tf_state_bucket_destroy }}
        REPO_ENV: ${{ inputs.repo_env }}
        GHS_ENV: ${{ inputs.dot_env }}
        GHV_ENV: ${{ inputs.ghv_env }}
        AWS_SECRET_ENV: ${{ inputs.aws_secret_env }}
        APP_PORT: ${{ inputs.app_port }}
        LB_PORT: ${{ inputs.lb_port }}
        LB_HEALTHCHECK: ${{ inputs.lb_healthcheck }}
        EC2_INSTANCE_PROFILE: ${{ inputs.ec2_instance_profile }}
        EC2_INSTANCE_TYPE: ${{ inputs.ec2_instance_type }}
        EC2_VOLUME_SIZE: ${{ inputs.ec2_volume_size }}
        STACK_DESTROY: ${{ inputs.stack_destroy }}
        ANSIBLE_START_DOCKER_TIMEOUT: ${{ inputs.ansible_start_docker_timeout }}
        AWS_RESOURCE_IDENTIFIER: ${{ inputs.aws_resource_identifier }}
        DOMAIN_NAME: ${{ inputs.domain_name }}
        SUB_DOMAIN: ${{ inputs.sub_domain }}
        ROOT_DOMAIN: ${{ inputs.root_domain }}
        CERT_ARN: ${{ inputs.cert_arn }}
        CREATE_ROOT_CERT: ${{ inputs.create_root_cert }}
        CREATE_SUB_CERT: ${{ inputs.create_sub_cert }}
        NO_CERT: ${{ inputs.no_cert }}
        BITOPS_FAST_FAIL: true
        DOCKER_REMOVE_ORPHANS: ${{ inputs.docker_remove_orphans }}
        DOCKER_FULL_CLEANUP: ${{ inputs.docker_full_cleanup }}
        APP_DIRECTORY: ${{ inputs.app_directory }}
        APP_DIRECTORY_CLEANUP: ${{ inputs.app_directory_cleanup }}
        CREATE_KEYPAIR_SM_ENTRY: ${{ inputs.create_keypair_sm_entry }}
        ADDITIONAL_TAGS: ${{ inputs.additional_tags }}
        AWS_ENABLE_POSTGRES: ${{ inputs.aws_enable_postgres }}
        AWS_POSTGRES_ENGINE:  ${{ inputs.aws_postgres_engine }}
        AWS_POSTGRES_ENGINE_VERSION:  ${{ inputs.aws_postgres_engine_version }}
        AWS_POSTGRES_DATABASE_GROUP_FAMILY: ${{ inputs.aws_postgres_database_group_family }}
        AWS_POSTGRES_INSTANCE_CLASS: ${{ inputs.aws_postgres_instance_class }}
        AWS_POSTGRES_SUBNETS: ${{ inputs.aws_postgres_subnets }}
        AWS_POSTGRES_DATABASE_NAME: ${{ inputs.aws_postgres_database_name }}
        AWS_POSTGRES_DATABASE_PORT: ${{ inputs.aws_postgres_database_port}}
        AWS_POSTGRES_DATABASE_PROTECTION: ${{ inputs.aws_postgres_database_protection }}
        AWS_POSTGRES_DATABASE_FINAL_SNAPSHOT: ${{ inputs.aws_postgres_database_final_snapshot }}
        AWS_CREATE_EFS: ${{ inputs.aws_create_efs }}
        AWS_CREATE_HA_EFS: ${{ inputs.aws_create_ha_efs }}
        AWS_CREATE_EFS_REPLICA: ${{ inputs.aws_create_efs_replica }}
        AWS_ENABLE_EFS_BACKUP_POLICY: ${{ inputs.aws_enable_efs_backup_policy }}
        AWS_EFS_ZONE_MAPPING: ${{ inputs.aws_efs_zone_mapping }}
        AWS_EFS_TRANSITION_TO_INACTIVE: ${{ inputs.aws_efs_transition_to_inactive }}
        AWS_EFS_REPLICA_DESTINATION: ${{ inputs.aws_replication_configuration_destination }}
        AWS_MOUNT_EFS_ID: ${{ inputs.aws_mount_efs_id }}
        AWS_MOUNT_EFS_SECURITY_GROUP_ID: ${{ inputs.aws_mount_efs_security_group_id }}
        APPLICATION_MOUNT_TARGET: ${{ inputs.application_mount_target }}
        EFS_MOUNT_TARGET: ${{ inputs.efs_mount_target }}
        DATA_MOUNT_TARGET: ${{ inputs.data_mount_target }}

      run: |
        echo "running operations/_scripts/deploy/deploy.sh"
        $GITHUB_ACTION_PATH/operations/_scripts/deploy/deploy.sh
        echo "running operations/_scripts/deploy/export_vars.sh"
        $GITHUB_ACTION_PATH/operations/_scripts/deploy/export_vars.sh

    # output results to GitHub
    - if: ${{ success() && steps.deploy.outputs.vm_url != '' }}
      name: Print result created
      shell: bash
      run: |
        echo "## VM Created! :rocket:" >> $GITHUB_STEP_SUMMARY
        echo " ${{ steps.deploy.outputs.vm_url }}" >> $GITHUB_STEP_SUMMARY
    - if: ${{ success() && steps.deploy.outputs.vm_url == '' && inputs.stack_destroy == 'true' && inputs.tf_state_bucket_destroy == 'false' }}
      name: Print result destroyed
      shell: bash
      run: |
        echo "## VM Destroyed! :boom:" >> $GITHUB_STEP_SUMMARY
        echo "Infrastructure should be gone now!" >> $GITHUB_STEP_SUMMARY
    - if: ${{ success() && steps.deploy.outputs.vm_url == '' && inputs.stack_destroy == 'true' && inputs.tf_state_bucket_destroy == 'true' }}
      name: Print result destroyed
      shell: bash
      run: |
        echo "## VM Destroyed! :boom:" >> $GITHUB_STEP_SUMMARY
        echo "Buckets and infrastructure should be gone now!" >> $GITHUB_STEP_SUMMARY
    - if: ${{ success() && steps.deploy.outputs.vm_url == '' && inputs.stack_destroy == 'false' }}
      name: Print result destroyed
      shell: bash
      run: |
        echo "## Deploy finished! But no URL found. :thinking: " >> $GITHUB_STEP_SUMMARY
        echo "If expecting an URL, please check the logs for possible  errors." >> $GITHUB_STEP_SUMMARY
        echo "If you consider this is a bug in the Github Action, please submit an issue to our repo." >> $GITHUB_STEP_SUMMARY
    - if: ${{ failure() }} 
      name: Print error result
      shell: bash
      run: |
        echo "## Workflow failed to run :fire:" >> $GITHUB_STEP_SUMMARY
        echo "Please check the logs for possible errors." >> $GITHUB_STEP_SUMMARY
        echo "If you consider this is a bug in the Github Action, please submit an issue to our repo." >> $GITHUB_STEP_SUMMARY
